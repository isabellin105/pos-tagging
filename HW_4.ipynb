{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5KTrLJKD-l7",
        "colab_type": "text"
      },
      "source": [
        "# Homework 4: Neural Sequence Labeling\n",
        "\n",
        "**Due March 4, 2020 at 11:59PM**\n",
        "\n",
        "\n",
        "In this homework, you will be implementing, training, and evaluating an LSTM for part-of-speech tagging using the PyTorch library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFgEH9BWEqPV",
        "colab_type": "text"
      },
      "source": [
        "**Before beginning, please switch your Colab session to a GPU runtime** \n",
        "\n",
        "Go to Runtime > Change runtime type > Hardware accelerator > GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xALTxzWIEkkE",
        "colab_type": "text"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk8GRWIkbrU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence, pad_packed_sequence, pack_padded_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t87Vex5_b5MI",
        "colab_type": "code",
        "outputId": "1b74edb9-d1d3-4ed7-e333-2a72b3960a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# if this cell prints \"Running on cpu\", you must switch runtime environments\n",
        "# go to Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on {}\".format(device))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3nDS9MwFCVf",
        "colab_type": "text"
      },
      "source": [
        "### Download & Load Pretrained Embeddings\n",
        "\n",
        "In this assignment, we will be using GloVe pretrained word embeddings. You can read more about GloVe here: https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "**Note**: this section will take *several minutes*, since the embedding files are large. Files in Colab may be cached between sessions, so you may or may not need to redownload the files each time you reconnect. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csWld6ckFNL1",
        "colab_type": "code",
        "outputId": "1c195c3b-61c4-4489-ef4c-2c47209e1dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "# download pretrained word embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-04 07:48:38--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-03-04 07:48:43--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-03-04 07:48:43--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.09MB/s    in 6m 27s  \n",
            "\n",
            "2020-03-04 07:55:10 (2.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiuJ5eylL0A0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_embeddings(filename, vocab_size=10000):\n",
        "  \"\"\"\n",
        "  Utility function, loads in the `vocab_size` most common embeddings from `filename`\n",
        "  \n",
        "  Arguments:\n",
        "  - filename:     path to file\n",
        "                  automatically infers correct embedding dimension from filename\n",
        "  - vocab_size:   maximum number of embeddings to load\n",
        "\n",
        "  Returns \n",
        "  - embeddings:   torch.FloatTensor matrix of size (vocab_size x word_embedding_dim)\n",
        "  - vocab:        dictionary mapping word (str) to index (int) in embedding matrix\n",
        "  \"\"\"\n",
        "\n",
        "  # get the embedding size from the first embedding\n",
        "  with open(filename, encoding=\"utf-8\") as file:\n",
        "    word_embedding_dim = len(file.readline().split(\" \")) - 1\n",
        "\n",
        "  vocab = {}\n",
        "\n",
        "  embeddings = np.zeros((vocab_size, word_embedding_dim))\n",
        "\n",
        "  with open(filename, encoding=\"utf-8\") as file:\n",
        "    for idx, line in enumerate(file):\n",
        "\n",
        "      if idx + 2 >= vocab_size:\n",
        "        break\n",
        "\n",
        "      cols = line.rstrip().split(\" \")\n",
        "      val = np.array(cols[1:])\n",
        "      word = cols[0]\n",
        "      embeddings[idx + 2] = val\n",
        "      vocab[word] = idx + 2\n",
        "  \n",
        "  # a FloatTensor is a multidimensional matrix\n",
        "  # that contains 32-bit floats in every entry\n",
        "  # https://pytorch.org/docs/stable/tensors.html\n",
        "  return torch.FloatTensor(embeddings), vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ah3clY7lHNZ",
        "colab_type": "text"
      },
      "source": [
        "Running the cell below lists all the files in the current directory. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D__oK6mQ6hs",
        "colab_type": "code",
        "outputId": "41ae4039-ba20-4a29-8588-be3d71f95f6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!ls -lh"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 2.9G\n",
            "-rw-rw-r-- 1 root root 332M Aug  4  2014 glove.6B.100d.txt\n",
            "-rw-rw-r-- 1 root root 662M Aug  4  2014 glove.6B.200d.txt\n",
            "-rw-rw-r-- 1 root root 990M Aug 27  2014 glove.6B.300d.txt\n",
            "-rw-rw-r-- 1 root root 164M Aug  4  2014 glove.6B.50d.txt\n",
            "-rw-r--r-- 1 root root 823M Oct 25  2015 glove.6B.zip\n",
            "drwxr-xr-x 1 root root 4.0K Feb  5 18:37 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoSWrCwZllg6",
        "colab_type": "text"
      },
      "source": [
        "You should see several embedding files, which are all formatted as\n",
        "\n",
        "```\n",
        "glove.6B.<emb_dim>d.txt\n",
        "```\n",
        "\n",
        "Each `txt` file contains `emb_dim` dimensional embeddings for 400,000 unique, uncased words. The script below loads the `vocab_size` most common words from the embedding file into a matrix we can give to our model. All other words will later be mapped to the `UNKNOWN` embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL8WuEZoOFbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this loads the 10,000 most common word 50-dimensional embeddings\n",
        "vocab_size = 10000\n",
        "embeddings, vocab = read_embeddings('glove.6B.50d.txt', vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py9AStUOJnPB",
        "colab_type": "text"
      },
      "source": [
        "## Part 1: Batching the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5jWl-z8w_5t",
        "colab_type": "text"
      },
      "source": [
        "Implement the `get_batches` function in the `Dataset` class below. \n",
        "\n",
        "**Please make sure that**\n",
        "\n",
        "*   Your implementation is self-contained. That is, all helper functions and variables are defined within `get_batches`.\n",
        "*   Your implementation can handle variable batch sizes. You may not assume that the value with always be 32\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KWyqb2HcLop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset():\n",
        "  def __init__(self, filename, is_labeled):\n",
        "    self.is_labeled = is_labeled\n",
        "    # if the file is not labeled, the Dataset has no tags (see read_data)\n",
        "    if is_labeled:\n",
        "      self.sentences, self.tags = self.read_data(filename, is_labeled)\n",
        "    else:\n",
        "      self.sentences = self.read_data(filename, is_labeled)\n",
        "      self.tags = None\n",
        "\n",
        "  def read_data(self, filename, is_labeled):\n",
        "    \"\"\"\n",
        "    Utility function, loads text file into a list of sentence and tag strings\n",
        "\n",
        "    Arguments:\n",
        "    - filename:     path to file\n",
        "    - is_labeled:   whether the file contains tags for each word or not\n",
        "        > if True, we assume each line is formatted as \"<word>\\t<tag>\\n\"\n",
        "        > if False, we assume each line is formatted as \"<word>\\n\"\n",
        "\n",
        "    Returns:\n",
        "    - sentences:    a list of sentences, where each sentence is a list \n",
        "                    words (strings)\n",
        "\n",
        "    if is_labeled=True, also returns\n",
        "    - tags:         a list of tags for each sentence, where tags[i] contains\n",
        "                    a list of tags (strings) that correspond to the words in \n",
        "                    sentences[i]\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "    tags = []\n",
        "\n",
        "    current_sentence = []\n",
        "    current_tags = []\n",
        "\n",
        "    with open(filename, encoding='utf8') as f:\n",
        "      # iterate over the lines in the file\n",
        "      for line in f:\n",
        "        if len(line) == 0:\n",
        "          continue\n",
        "        if line == '\\n':\n",
        "          if len(current_sentence) != 0:\n",
        "            sentences.append(current_sentence)\n",
        "            tags.append(current_tags)\n",
        "\n",
        "          current_sentence = []\n",
        "          current_tags = []\n",
        "        else:\n",
        "          if is_labeled:\n",
        "            columns = line.rstrip().split('\\t')\n",
        "            word = columns[0].lower()\n",
        "            tag = columns[1]\n",
        "\n",
        "            current_sentence.append(word)\n",
        "            current_tags.append(tag)\n",
        "          else:\n",
        "            column = line.rstrip().split('\\t')\n",
        "            word = column[0].lower()\n",
        "            current_sentence.append(word)\n",
        "      \n",
        "      if is_labeled:\n",
        "        return sentences, tags\n",
        "      else:\n",
        "        return sentences\n",
        "\n",
        "  def get_batches(self, batch_size, vocab, tagset):\n",
        "    \"\"\"\n",
        "\n",
        "    Batches the data into mini-batches of size `batch_size`\n",
        "\n",
        "    Arguments:\n",
        "    - batch_size:       the desired output batch size\n",
        "    - vocab:            a dictionary mapping word strings to indices\n",
        "    - tagset:           a dictionary mapping tag strings to indices\n",
        "\n",
        "    Outputs:\n",
        "\n",
        "    if is_labeled=True:\n",
        "    - batched_word_indices:     a list of matrices of dimension (batch_size x max_seq_len)\n",
        "    - batched_tag_indices:      a list of matrices of dimension (batch_size x max_seq_len)\n",
        "    - batched_lengths:          a list of arrays of length (batch_size)\n",
        "\n",
        "    if is_labeled=False:\n",
        "    - batched_word_indices:     a list of matrices of dimension (batch_size x max_seq_len)\n",
        "    - batched_lengths:          a list of arrays of length (batch_size)\n",
        "\n",
        "\n",
        "    Description: \n",
        "\n",
        "    This function partitions the data into batches of size batch_size. If the number\n",
        "    of sentences in the document is not an even multiple of batch_size, the final batch\n",
        "    will contain the remaining elements. For example, if there are 82 sentences in the \n",
        "    dataset and batch_size=32, we return a list containing two batches of size 32 \n",
        "    and one final batch of size 18.\n",
        "\n",
        "    batched_word_indices[b] is a (batch_size x max_seq_len) matrix of integers, \n",
        "    containing index representations for sentences in the b-th batch in the document. \n",
        "    The `vocab` dictionary provides the correct mapping from word strings to indices. \n",
        "    If a word is not in the vocabulary, it gets mapped to UNKNOWN_INDEX (1).\n",
        "    `max_seq_len` is the maximum sentence length among the sentences in the current batch, \n",
        "    which will vary between different batches. All sentences shorter than max_seq_len \n",
        "    should be padded on the right with PAD_INDEX (0).\n",
        "\n",
        "    If the document is labeled, we also batch the document's tags. Analogous to \n",
        "    batched_word_indices, batched_tag_indices[b] contains the index representation\n",
        "    for the tags corresponding to the sentences in the b-th batch  in the document. \n",
        "    The `tagset` dictionary provides the correct mapping from tag strings to indicies. \n",
        "    All tag lists shorter than `max_seq_len` are padded with IGNORE_TAG_INDEX (-100).\n",
        "\n",
        "    batched_lengths[b] is a vector of length (batch_size). batched_lengths[b][i] \n",
        "    contains the original sentence length *before* padding for the i-th sentence\n",
        "    in the currrent batch. \n",
        "\n",
        "    \"\"\"\n",
        "    PAD_INDEX = 0             # reserved for padding words\n",
        "    UNKNOWN_INDEX = 1         # reserved for unknown words\n",
        "    IGNORE_TAG_INDEX = -100   # reserved for padding tags\n",
        "\n",
        "    # randomly shuffle the data\n",
        "    np.random.seed(159) # DON'T CHANGE THIS\n",
        "    shuffle = np.random.permutation(range(len(self.sentences)))\n",
        "\n",
        "    sentences = [self.sentences[i] for i in shuffle]\n",
        "    if self.is_labeled:\n",
        "      tags = [self.tags[i] for i in shuffle]\n",
        "    else:\n",
        "      tags = None\n",
        "\n",
        "    batched_word_indices = []\n",
        "    batched_tag_indices = []\n",
        "    batched_lengths = []\n",
        "\n",
        "    #############################\n",
        "    batches = [sentences[i * batch_size:(i + 1) * batch_size] for i in range((len(sentences) + batch_size - 1) // batch_size )]  \n",
        "    \n",
        "    if tags != None:\n",
        "      tag_batches = [tags[i * batch_size:(i + 1) * batch_size] for i in range((len(tags) + batch_size - 1) // batch_size )]  \n",
        "\n",
        "    for i in np.arange(len(batches)):\n",
        "      batched_word_indices.append([])\n",
        "      for sentence in batches[i]:\n",
        "          batched_word_indices[i].append([vocab[word] if word in vocab else UNKNOWN_INDEX for word in sentence])\n",
        "    \n",
        "    if self.tags != None:\n",
        "      for i in np.arange(len(tag_batches)):\n",
        "        batched_tag_indices.append([])\n",
        "        for sentence in tag_batches[i]:\n",
        "            batched_tag_indices[i].append([tagset[tag] for tag in sentence])\n",
        "    \n",
        "    for i in np.arange(len(batches)):\n",
        "      batched_lengths.append(np.asarray([len(sentence) for sentence in batches[i]]))\n",
        "\n",
        "    for i in np.arange(len(batched_word_indices)):\n",
        "      max_seq_len = np.amax(batched_lengths[i])\n",
        "      batched_word_indices[i] = [np.pad(np.asarray(sentence),(0, max_seq_len-len(sentence))) if len(sentence)<max_seq_len else np.asarray(sentence) for sentence in batched_word_indices[i]]\n",
        "      batched_word_indices[i] = np.asarray(batched_word_indices[i])\n",
        "      if self.tags != None:\n",
        "        batched_tag_indices[i] = [np.pad(np.asarray(sentence),(0, max_seq_len-len(sentence)),mode = 'constant', constant_values=(IGNORE_TAG_INDEX)) \n",
        "        if len(sentence)<max_seq_len else np.asarray(sentence) for sentence in batched_tag_indices[i]]\n",
        "        batched_tag_indices[i] = np.asarray(batched_tag_indices[i])\n",
        "\n",
        "    #############################\n",
        "\n",
        "    \n",
        "\n",
        "    #############################\n",
        "    #       DO NOT MODIFY       #\n",
        "    #############################\n",
        "    if self.is_labeled:\n",
        "      return batched_word_indices, batched_tag_indices, batched_lengths\n",
        "    else:\n",
        "      return batched_word_indices, batched_lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUrpF-y27Gza",
        "colab_type": "code",
        "outputId": "dcaa55ce-7f73-4381-b370-b3549a7599cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\"\"\"\n",
        "batch_size = 2\n",
        "vocab_test = {'This':1, \"is\":2}\n",
        "tagset = {'to':1, \"a\":2}\n",
        "batched_lengths = []\n",
        "batched_word_indices = []\n",
        "batched_tag_indices = []\n",
        "\n",
        "UNKNOWN_INDEX = 0\n",
        "IGNORE_TAG_INDEX = -100\n",
        "PAD_INDEX = 0\n",
        "sentences = [\n",
        "\t['This', 'is', 'an', 'example', 'sentence', '.'],\n",
        "\t['Another', 'example', '.'],\n",
        "\t['I', 'like', 'NLP', '.']\n",
        "]\n",
        "tags = [\n",
        "\t['to', 'a', 'to', 'to', 'to', 'to'],\n",
        "\t['to', 'to', 'to'],\n",
        "\t['to', 'to', 'to', 'to']\n",
        "]\n",
        "batches = [sentences[i * batch_size:(i + 1) * batch_size] for i in range((len(sentences) + batch_size - 1) // batch_size )]  \n",
        "\n",
        "for i in np.arange(len(batches)):\n",
        "  batched_word_indices.append([])\n",
        "  for sentence in batches[i]:\n",
        "      batched_word_indices[i].append([vocab_test[word] if word in vocab else UNKNOWN_INDEX for word in sentence])\n",
        "\n",
        "tag_batches = [tags[i * batch_size:(i + 1) * batch_size] for i in range((len(tags) + batch_size - 1) // batch_size )]  \n",
        "\n",
        "for i in np.arange(len(tag_batches)):\n",
        "    batched_tag_indices.append([])\n",
        "    for sentence in tag_batches[i]:\n",
        "        batched_tag_indices[i].append([tagset[tag] for tag in sentence])\n",
        "\n",
        "for i in np.arange(len(batches)):\n",
        "  batched_lengths.append(np.asarray([len(sentence) for sentence in batches[i]]))\n",
        "\n",
        "for i in np.arange(len(batched_word_indices)):\n",
        "  max_seq_len = np.amax(batched_lengths[i])\n",
        "  batched_word_indices[i] = [np.pad(np.asarray(sentence),(0, max_seq_len-len(sentence))) if len(sentence)<max_seq_len else np.asarray(sentence) for sentence in batched_word_indices[i]]\n",
        "  batched_word_indices[i] = np.asarray(batched_word_indices[i])\n",
        "  batched_tag_indices[i] = [np.pad(np.asarray(sentence),(0, max_seq_len-len(sentence)),mode = 'constant', constant_values=(IGNORE_TAG_INDEX)) \n",
        "        if len(sentence)<max_seq_len else np.asarray(sentence) for sentence in batched_tag_indices[i]]\n",
        "  batched_tag_indices[i] = np.asarray(batched_tag_indices[i])\n",
        "\n",
        "print (batched_lengths)\n",
        "print (batched_word_indices)\n",
        "print (batched_tag_indices)\n",
        "\"\"\"\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nbatch_size = 2\\nvocab_test = {\\'This\\':1, \"is\":2}\\ntagset = {\\'to\\':1, \"a\":2}\\nbatched_lengths = []\\nbatched_word_indices = []\\nbatched_tag_indices = []\\n\\nUNKNOWN_INDEX = 0\\nIGNORE_TAG_INDEX = -100\\nPAD_INDEX = 0\\nsentences = [\\n\\t[\\'This\\', \\'is\\', \\'an\\', \\'example\\', \\'sentence\\', \\'.\\'],\\n\\t[\\'Another\\', \\'example\\', \\'.\\'],\\n\\t[\\'I\\', \\'like\\', \\'NLP\\', \\'.\\']\\n]\\ntags = [\\n\\t[\\'to\\', \\'a\\', \\'to\\', \\'to\\', \\'to\\', \\'to\\'],\\n\\t[\\'to\\', \\'to\\', \\'to\\'],\\n\\t[\\'to\\', \\'to\\', \\'to\\', \\'to\\']\\n]\\nbatches = [sentences[i * batch_size:(i + 1) * batch_size] for i in range((len(sentences) + batch_size - 1) // batch_size )]  \\n\\nfor i in np.arange(len(batches)):\\n  batched_word_indices.append([])\\n  for sentence in batches[i]:\\n      batched_word_indices[i].append([vocab_test[word] if word in vocab else UNKNOWN_INDEX for word in sentence])\\n\\ntag_batches = [tags[i * batch_size:(i + 1) * batch_size] for i in range((len(tags) + batch_size - 1) // batch_size )]  \\n\\nfor i in np.arange(len(tag_batches)):\\n    batched_tag_indices.append([])\\n    for sentence in tag_batches[i]:\\n        batched_tag_indices[i].append([tagset[tag] for tag in sentence])\\n\\nfor i in np.arange(len(batches)):\\n  batched_lengths.append(np.asarray([len(sentence) for sentence in batches[i]]))\\n\\nfor i in np.arange(len(batched_word_indices)):\\n  max_seq_len = np.amax(batched_lengths[i])\\n  batched_word_indices[i] = [np.pad(np.asarray(sentence),(0, max_seq_len-len(sentence))) if len(sentence)<max_seq_len else np.asarray(sentence) for sentence in batched_word_indices[i]]\\n  batched_word_indices[i] = np.asarray(batched_word_indices[i])\\n  batched_tag_indices[i] = [np.pad(np.asarray(sentence),(0, max_seq_len-len(sentence)),mode = \\'constant\\', constant_values=(IGNORE_TAG_INDEX)) \\n        if len(sentence)<max_seq_len else np.asarray(sentence) for sentence in batched_tag_indices[i]]\\n  batched_tag_indices[i] = np.asarray(batched_tag_indices[i])\\n\\nprint (batched_lengths)\\nprint (batched_word_indices)\\nprint (batched_tag_indices)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ePEcb46_zGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_tagset(tag_file):\n",
        "  \"\"\"\n",
        "  Utility function, loads tag file into a dictionary from tag string to tag index\n",
        "\n",
        "  Arguments:\n",
        "  - tag_file:   file location of the tagset\n",
        "\n",
        "  Outputs:\n",
        "  - tagset:     a dictionary mapping tag strings (e.g. \"VB\") to a unique index\n",
        "  \"\"\"\n",
        "  tagset = {}\n",
        "  with open(tag_file, encoding='utf8') as f:\n",
        "    for line in f:\n",
        "      columns = line.rstrip().split('\\t')\n",
        "      tag = columns[0]\n",
        "      tag_id = int(columns[1])\n",
        "      tagset[tag] = tag_id\n",
        "  \n",
        "  return tagset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok4MaVEhDp2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mMQIJ_vVuiz",
        "colab_type": "text"
      },
      "source": [
        "The cells below download the data files and construct the corresponding `Dataset` objects. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhXTkpTqGR1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/dbamman/nlp20/master/HW_4/pos.train\n",
        "!wget https://raw.githubusercontent.com/dbamman/nlp20/master/HW_4/pos.dev\n",
        "!wget https://raw.githubusercontent.com/dbamman/nlp20/master/HW_4/pos.test\n",
        "!wget https://raw.githubusercontent.com/dbamman/nlp20/master/HW_4/pos.tagset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vtP5seIgBORT",
        "colab": {}
      },
      "source": [
        "# read the files\n",
        "tagset = read_tagset('pos.tagset')\n",
        "train_dataset = Dataset('pos.train', is_labeled=True)\n",
        "dev_dataset = Dataset('pos.dev', is_labeled=True)\n",
        "test_dataset = Dataset('pos.test', is_labeled=False)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# these should run without errors if implemented correctly\n",
        "train_batch_idx, train_batch_tags, train_batch_lens = train_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
        "dev_batch_idx, dev_batch_tags, dev_batch_lens = dev_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
        "test_batch_idx, test_batch_lens = test_dataset.get_batches(BATCH_SIZE, vocab, tagset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-nnX7WxqDJ3",
        "colab_type": "text"
      },
      "source": [
        "### Part 2: Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMtkCBt_wzIS",
        "colab_type": "text"
      },
      "source": [
        "Next, we will implement utility functions that will later be used to assess our model's perfomance. \n",
        "\n",
        "**Please make sure that**\n",
        "\n",
        "*   Your implementation is self-contained. That is, keep all helper functions or variables inside of your function.\n",
        "*   Your implementation does not import any additional libraries. You will not receive credit if you do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQLiM0ukG-4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The accuracy function has been implemented for you\n",
        "\n",
        "def accuracy(true, pred):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  - true:       a list of true label values (integers)\n",
        "  - pred:       a list of predicted label values (integers)\n",
        "\n",
        "  Output:\n",
        "  - accuracy:   the prediction accuracy\n",
        "  \"\"\"\n",
        "  true = np.array(true)\n",
        "  pred = np.array(pred)\n",
        "\n",
        "  num_correct = sum(true == pred)\n",
        "  num_total = len(true)\n",
        "  return num_correct / num_total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChJjUu45qFM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def confusion_matrix(true, pred, num_tags):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  - true:       a list of true label values (integers)\n",
        "  - pred:       a list of predicted label values (integers)\n",
        "  - num_tags:   the number of possible tags\n",
        "                true and pred will both contain integers between\n",
        "                0 and num_tags - 1 (inclusive)\n",
        "\n",
        "  Output: \n",
        "  - confusion_matrix:   a (num_tags x num_tags) matrix of integers\n",
        "\n",
        "  confusion_matrix[i][j] = # predictions where true label\n",
        "  was i and predicted label was j\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  confusion_matrix = np.zeros((num_tags, num_tags))\n",
        "\n",
        "  #############################\n",
        "  \"\"\"\n",
        "  for tag in np.arange(len(num_tags)):\n",
        "    tp.append(sum(true == pred == tag))\n",
        "    fp.append(sum(pred == tag and true != tag))\n",
        "    fn.append(sum(pred != tag and true == tag))\n",
        "  \n",
        "  for i in np.arange(num_tags):\n",
        "    for j in np.arange(num_tags):\n",
        "      if i == j:\n",
        "        confusion_matrix[i][j] = sum(np.logical_and(true == i, pred == i))\n",
        "      else:\n",
        "        confusion_matrix[i][j] = sum(np.logical_and(pred == j, true == i))\n",
        "  \"\"\"\n",
        "  for t in np.arange(len(true)):\n",
        "    i = true[t]\n",
        "    j = pred[t]\n",
        "    confusion_matrix[i][j] += 1  \n",
        "  #############################\n",
        "\n",
        "  \n",
        "\n",
        "  return confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hdj6QSaBV9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precision(true, pred, num_tags):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  - true:       a list of true label values (integers)\n",
        "  - pred:       a list of predicted label values (integers)\n",
        "  - num_tags:   the number of possible tags\n",
        "                true and pred will both contain integers between\n",
        "                0 and num_tags - 1 (inclusive)\n",
        "\n",
        "  Output: \n",
        "  - precision:  an array of length num_tags, where precision[i]\n",
        "                gives the precision of class i\n",
        "\n",
        "  Hints:  the confusion matrix may be useful\n",
        "          be careful about zero division\n",
        "  \"\"\"\n",
        "\n",
        "  precision = np.zeros(num_tags)\n",
        "\n",
        "  #############################\n",
        "  cm = confusion_matrix(true, pred, num_tags)\n",
        "  for i in np.arange(num_tags):\n",
        "    if (sum([cm[x][i] for x in np.arange(num_tags)])==0):\n",
        "      precision[i] = 0\n",
        "    else:\n",
        "      precision[i] = cm[i][i]/sum([cm[x][i] for x in np.arange(num_tags)])\n",
        "  #############################\n",
        "\n",
        "\n",
        "  \n",
        "  return precision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJL55TnOBVxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall(true, pred, num_tags):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  - true:       a list of true label values (integers)\n",
        "  - pred:       a list of predicted label values (integers)\n",
        "  - num_tags:   the number of possible tags\n",
        "                true and pred will both contain integers between\n",
        "                0 and num_tags - 1 (inclusive)\n",
        "\n",
        "  Output: \n",
        "  - recall:     an array of length num_tags, where recall[i]\n",
        "                gives the recall of class i\n",
        "\n",
        "  Hints:  the confusion matrix may be useful\n",
        "          be careful about zero division\n",
        "  \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "  YOUR CODE HERE\n",
        "  \"\"\"\n",
        "  recall = np.zeros(num_tags)\n",
        "\n",
        "  #############################\n",
        "  cm = confusion_matrix(true, pred, num_tags)\n",
        "  for i in np.arange(num_tags):\n",
        "    if (sum([cm[i][x] for x in np.arange(num_tags)])==0):\n",
        "      recall[i] = 0\n",
        "    else:\n",
        "      recall[i] = cm[i][i]/sum([cm[i][x] for x in np.arange(num_tags)])\n",
        "  #############################\n",
        "\n",
        "\n",
        "  return recall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7drr7z1VBVjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1_score(true, pred, num_tags):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  - true:       a list of true label values (integers)\n",
        "  - pred:       a list of predicted label values (integers)\n",
        "  - num_tags:   the number of possible tags\n",
        "                true and pred will both contain integers between\n",
        "                0 and num_tags - 1 (inclusive)\n",
        "\n",
        "  Output: \n",
        "  - f1:         an array of length num_tags, where f1[i]\n",
        "                gives the recall of class i\n",
        "  \"\"\"\n",
        "  f1 = np.zeros(num_tags)\n",
        "\n",
        "  #############################\n",
        "  p = precision(true, pred, num_tags)\n",
        "  r = recall(true, pred, num_tags)\n",
        "\n",
        "  for i in np.arange(num_tags):\n",
        "    if p[i]+r[i] == 0:\n",
        "      f1[i] = 0\n",
        "    else:\n",
        "      f1[i]= (2*(p[i]*r[i])/(p[i]+r[i]))\n",
        "  #############################\n",
        "\n",
        "\n",
        "  return f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS1p55P5UGv4",
        "colab_type": "text"
      },
      "source": [
        "### Part 3: Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IPoFwqfoFOO",
        "colab_type": "text"
      },
      "source": [
        "Fill in the blanks in `LSTMTagger`'s `__init__` function. If you get stuck, you can reference PyTorch's [torch.nn documentation](https://pytorch.org/docs/stable/nn.html) or [this official tutorial](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html) on LSTM sequence labeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6J3z3T0USI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "  \"\"\"\n",
        "  An LSTM model for sequence labeling\n",
        "\n",
        "  Initialization Arguments:\n",
        "  - embeddings:   a matrix of size (vocab_size, emb_dim)\n",
        "                  containing pretrained embedding weights\n",
        "  - hidden_dim:   the LSTM's hidden layer size\n",
        "  - tagset_size:  the number of possible output tags\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, embeddings, hidden_dim, tagset_size):\n",
        "    super().__init__()\n",
        "  \n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.num_labels = tagset_size\n",
        "\n",
        "    #############################\n",
        "    #       YOUR CODE HERE      #\n",
        "    #############################\n",
        "\n",
        "    # Initialize a PyTorch embeddings layer using the pretrained embedding weights\n",
        "    self.embeddings = nn.Embedding.from_pretrained(embeddings, freeze = False)\n",
        "\n",
        "    # Initialize an LSTM layer, shape batch_size x sequence_len\n",
        "    self.lstm = nn.LSTM(input_size=embeddings.size()[1], hidden_size=hidden_dim, num_layers=1)\n",
        "\n",
        "\n",
        "    # Initialize a single feedforward layer\n",
        "    self.hidden2tag = nn.Linear(self.hidden_dim, self.num_labels)\n",
        "  \n",
        "  def forward(self, indices, lengths):\n",
        "    \"\"\"\n",
        "    Runs a batched sequence through the model and returns output logits\n",
        "\n",
        "    Arguments:\n",
        "    - indices:  a matrix of size (batch_size x max_seq_len)\n",
        "                containing the word indices of sentences in the batch\n",
        "    - lengths:  a vector of size (batch_size) containing the\n",
        "                original lengths of the sequences before padding\n",
        "\n",
        "    Output:\n",
        "    - logits:   a matrix of size (batch_size x max_seq_len x num_tags)\n",
        "                gives a score to each possible tag for each word\n",
        "                in each sentence \n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # cast arrays as PyTorch data types and move to GPU memory\n",
        "    indices = torch.LongTensor(indices).to(device)\n",
        "    lengths = torch.LongTensor(lengths).to(device)\n",
        "    \n",
        "    # convert word indices to word embeddings\n",
        "    embeddings = self.embeddings(indices)\n",
        "\n",
        "    # pack/pad handles variable length sequence batching\n",
        "    # see here if you're curious: https://gist.github.com/HarshTrivedi/f4e7293e941b17d19058f6fb90ab0fec\n",
        "    packed_input_embs = pack_padded_sequence(embeddings, lengths, batch_first=True, enforce_sorted=False)\n",
        "    # run input through LSTM layer\n",
        "    packed_output, _ = self.lstm(packed_input_embs)\n",
        "    # unpack sequences into original format\n",
        "    padded_output, output_lengths = pad_packed_sequence(packed_output, batch_first=True)\n",
        "\n",
        "    logits = self.hidden2tag(padded_output)\n",
        "    return logits\n",
        "\n",
        "  def run_training(self, train_dataset, dev_dataset, batch_size, vocab, tagset,\n",
        "                         lr=5e-4, num_epochs=100, eval_every=5):\n",
        "    \"\"\"\n",
        "    Trains the model on the training data with a learning rate of lr\n",
        "    for num_epochs. Evaluates the model on the dev data eval_every epochs.\n",
        "\n",
        "    Arguments:\n",
        "    - train_dataset:  Dataset object containing the training data\n",
        "    - dev_dataset:    Dataset object containing the dev data\n",
        "    - batch_size:     batch size for train/dev data\n",
        "    - vocab:          a dictionary mapping word strings to indices\n",
        "    - tagset:         a dictionary mapping tag strings to indices\n",
        "    - lr:             learning rate\n",
        "    - num_epochs:     number of epochs to train for\n",
        "    - eval_every:     evaluation is run eval_every epochs\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    if str(device) == 'cpu':\n",
        "      print(\"Training only supported in GPU environment\")\n",
        "      return\n",
        "\n",
        "    # clear unreferenced data/models from GPU memory \n",
        "    torch.cuda.empty_cache()\n",
        "    # move model to GPU memory\n",
        "    self.to(device)\n",
        "\n",
        "    # set the optimizer (Adam) and loss function (CrossEnt)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_function = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "\n",
        "    # batch training and dev data\n",
        "    train_batch_idx, train_batch_tags, train_batch_lens = train_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
        "    dev_batch_idx, dev_batch_tags, dev_batch_lens = dev_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
        "\n",
        "    print(\"**** TRAINING *****\")\n",
        "    for i in range(num_epochs):\n",
        "      # sets the model in train mode\n",
        "      self.train()\n",
        "\n",
        "      total_loss = 0\n",
        "      for b in range(len(train_batch_idx)):\n",
        "        # compute the logits\n",
        "        logits = model.forward(train_batch_idx[b], train_batch_lens[b])\n",
        "        # move labels to GPU memory\n",
        "        labels = torch.LongTensor(train_batch_tags[b]).to(device)\n",
        "        # compute the loss with respect to true labels\n",
        "        loss = loss_function(logits.view(-1, len(tagset)), labels.view(-1))\n",
        "        total_loss += loss\n",
        "        # propagate gradients backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # set model gradients to zero before performing next forward pass\n",
        "        self.zero_grad()\n",
        "\n",
        "      print(\"Epoch {} | Loss: {}\".format(i, total_loss))\n",
        "\n",
        "      if (i + 1) % eval_every == 0:\n",
        "        print(\"**** EVALUATION *****\")\n",
        "        # sets the model in evaluate mode (no gradients)\n",
        "        self.eval()\n",
        "        # compute dev f1 score\n",
        "        acc, true, pred = self.evaluate(dev_batch_idx, dev_batch_lens, dev_batch_tags, tagset)\n",
        "        print(\"Dev Accuracy: {}\".format(acc))\n",
        "        print(\"**********************\")\n",
        "\n",
        "  def evaluate(self, batched_sentences, batched_lengths, batched_labels, tagset):\n",
        "    \"\"\"\n",
        "    Evaluate the model's predictions on the provided dataset. \n",
        "\n",
        "    Arguments:\n",
        "    - batched_sentences:  a list of matrices, each of size (batch_size x max_seq_len),\n",
        "                          containing the word indices of sentences in the batch\n",
        "    - batched_lengths:    a list of vectors, each of size (batch_size), containing the\n",
        "                          original lengths of the sequences before padding\n",
        "    - batched_labels:     a list of matrices, each of size (batch_size x max_seq_len),\n",
        "                          containing the tag indices corresponding to sentences in the batch\n",
        "    - num_tags:           the number of possible output tags\n",
        "\n",
        "    Output:\n",
        "    - accuracy:           the model's prediction accuracy\n",
        "    - all_true_labels:    a flattened list of all true labels\n",
        "    - all_predictions:    a flattened list of all of the model's corresponding predictions\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    all_true_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    for b in range(len(batched_sentences)):\n",
        "      logits = self.forward(batched_sentences[b], batched_lengths[b])\n",
        "      batch_predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "\n",
        "      batch_size, _ = batched_sentences[b].shape\n",
        "\n",
        "      for i in range(batch_size):\n",
        "        tags = batched_labels[b][i]\n",
        "        preds = batch_predictions[i]\n",
        "        \n",
        "        seq_len = int(batched_lengths[b][i])\n",
        "        for j in range(seq_len):\n",
        "          all_predictions.append(int(preds[j]))\n",
        "          all_true_labels.append(int(tags[j]))\n",
        "      \n",
        "    \n",
        "    acc = accuracy(all_true_labels, all_predictions)\n",
        "      \n",
        "    return acc, all_true_labels, all_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4AOB94R9RFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_seed(seed):\n",
        "  \"\"\"\n",
        "  Sets random seeds and sets model in deterministic\n",
        "  training mode. Ensures reproducible results\n",
        "  \"\"\"\n",
        "  torch.manual_seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AuNeDk9qAM_",
        "colab_type": "text"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WTEvLeVuNWl",
        "colab_type": "text"
      },
      "source": [
        "Run the cells below to train your model. If all of the previous sections are implemented correctly, you should see\n",
        "\n",
        "\n",
        "*   the loss decreasing consistently for every epoch\n",
        "*   the dev accuracy increasing until convergence around ~0.88\n",
        "\n",
        "The staff solution achieves an accuracy of 0.880 after 25 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9NqwYnfU2WB",
        "colab_type": "code",
        "outputId": "c588f074-5253-4553-9ced-1b543302122e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "source": [
        "# sets the random seed – DO NOT change this\n",
        "# this ensures deterministic results that are comparable with the staff values\n",
        "set_seed(159)\n",
        "\n",
        "HIDDEN_SIZE = 64\n",
        "# intialize a new LSTMTagger model\n",
        "model = LSTMTagger(embeddings, HIDDEN_SIZE, len(tagset))\n",
        "# train the model\n",
        "model.run_training(train_dataset, dev_dataset, BATCH_SIZE, vocab, tagset,   \n",
        "                   lr=5e-4, num_epochs=25, eval_every=5)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**** TRAINING *****\n",
            "Epoch 0 | Loss: 999.9422607421875\n",
            "Epoch 1 | Loss: 442.2580871582031\n",
            "Epoch 2 | Loss: 275.37127685546875\n",
            "Epoch 3 | Loss: 212.16624450683594\n",
            "Epoch 4 | Loss: 181.42295837402344\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.8586200039769338\n",
            "**********************\n",
            "Epoch 5 | Loss: 163.11807250976562\n",
            "Epoch 6 | Loss: 150.56387329101562\n",
            "Epoch 7 | Loss: 141.14601135253906\n",
            "Epoch 8 | Loss: 133.6881866455078\n",
            "Epoch 9 | Loss: 127.54783630371094\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.8754026645456353\n",
            "**********************\n",
            "Epoch 10 | Loss: 122.3573989868164\n",
            "Epoch 11 | Loss: 117.87614440917969\n",
            "Epoch 12 | Loss: 113.92591094970703\n",
            "Epoch 13 | Loss: 110.38809967041016\n",
            "Epoch 14 | Loss: 107.16902923583984\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.8791409823026447\n",
            "**********************\n",
            "Epoch 15 | Loss: 104.20204162597656\n",
            "Epoch 16 | Loss: 101.439453125\n",
            "Epoch 17 | Loss: 98.83808135986328\n",
            "Epoch 18 | Loss: 96.3730239868164\n",
            "Epoch 19 | Loss: 94.02764129638672\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.8803738317757009\n",
            "**********************\n",
            "Epoch 20 | Loss: 91.78711700439453\n",
            "Epoch 21 | Loss: 89.6347427368164\n",
            "Epoch 22 | Loss: 87.56659698486328\n",
            "Epoch 23 | Loss: 85.56128692626953\n",
            "Epoch 24 | Loss: 83.62176513671875\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.8802147544243388\n",
            "**********************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH5giKgvJp0c",
        "colab_type": "text"
      },
      "source": [
        "Once the model is trained, run the cells below to print the precision, recall, and $F_1$ score per class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLqaZ_6cMMPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_per_class(model, dataset, vocab, tagset):\n",
        "  \"\"\"\n",
        "  Prints precision, recall, and F1 for each class in the tagset\n",
        "  \"\"\"\n",
        "  # batch the data\n",
        "  batched_idx, batched_tags, batched_lens = dev_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
        "  # compute idx --> tag from tag --> idx\n",
        "  reverse_tagset = {v: k for k,v in tagset.items()}\n",
        "  # evaluate model on hold-out set\n",
        "  acc, true, pred = model.evaluate(batched_idx, batched_lens, batched_tags, tagset)\n",
        "  true = np.array(true)\n",
        "  pred = np.array(pred)\n",
        "\n",
        "  pr = precision(true, pred, len(tagset))\n",
        "  re = recall(true, pred, len(tagset))\n",
        "  f1 = f1_score(true, pred, len(tagset))\n",
        "\n",
        "  for idx, tag in reverse_tagset.items():\n",
        "    print(\"***********************\")\n",
        "    print(\"TAG: {}\".format(tag))\n",
        "    num_pred = np.sum(pred == idx)\n",
        "    num_true = np.sum(true == idx)\n",
        "    print(\"({} pred, {} true)\".format(num_pred, num_true))\n",
        "\n",
        "    print(\"PRECISION: \\t{:.3f}\".format(pr[idx]))\n",
        "    print(\"RECALL: \\t{:.3f}\".format(re[idx]))\n",
        "    print(\"F1 SCORE: \\t{:.3f}\".format(f1[idx]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tTEpCBsuYuP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5217
        },
        "outputId": "7d40b37a-a53a-4259-f511-991e59ce2862"
      },
      "source": [
        "eval_per_class(model, dev_dataset, vocab, tagset)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***********************\n",
            "TAG: $\n",
            "(13 pred, 14 true)\n",
            "PRECISION: \t1.000\n",
            "RECALL: \t0.929\n",
            "F1 SCORE: \t0.963\n",
            "***********************\n",
            "TAG: ''\n",
            "(90 pred, 88 true)\n",
            "PRECISION: \t0.822\n",
            "RECALL: \t0.841\n",
            "F1 SCORE: \t0.831\n",
            "***********************\n",
            "TAG: ,\n",
            "(927 pred, 936 true)\n",
            "PRECISION: \t0.958\n",
            "RECALL: \t0.949\n",
            "F1 SCORE: \t0.953\n",
            "***********************\n",
            "TAG: -LRB-\n",
            "(104 pred, 117 true)\n",
            "PRECISION: \t0.962\n",
            "RECALL: \t0.855\n",
            "F1 SCORE: \t0.905\n",
            "***********************\n",
            "TAG: -RRB-\n",
            "(115 pred, 120 true)\n",
            "PRECISION: \t0.896\n",
            "RECALL: \t0.858\n",
            "F1 SCORE: \t0.877\n",
            "***********************\n",
            "TAG: .\n",
            "(1446 pred, 1503 true)\n",
            "PRECISION: \t0.992\n",
            "RECALL: \t0.955\n",
            "F1 SCORE: \t0.973\n",
            "***********************\n",
            "TAG: :\n",
            "(117 pred, 106 true)\n",
            "PRECISION: \t0.821\n",
            "RECALL: \t0.906\n",
            "F1 SCORE: \t0.861\n",
            "***********************\n",
            "TAG: ADD\n",
            "(0 pred, 81 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: AFX\n",
            "(0 pred, 4 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: CC\n",
            "(769 pred, 781 true)\n",
            "PRECISION: \t0.991\n",
            "RECALL: \t0.976\n",
            "F1 SCORE: \t0.983\n",
            "***********************\n",
            "TAG: CD\n",
            "(366 pred, 378 true)\n",
            "PRECISION: \t0.760\n",
            "RECALL: \t0.735\n",
            "F1 SCORE: \t0.747\n",
            "***********************\n",
            "TAG: DT\n",
            "(1990 pred, 1943 true)\n",
            "PRECISION: \t0.960\n",
            "RECALL: \t0.983\n",
            "F1 SCORE: \t0.971\n",
            "***********************\n",
            "TAG: EX\n",
            "(44 pred, 56 true)\n",
            "PRECISION: \t0.909\n",
            "RECALL: \t0.714\n",
            "F1 SCORE: \t0.800\n",
            "***********************\n",
            "TAG: FW\n",
            "(0 pred, 30 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: GW\n",
            "(0 pred, 32 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: HYPH\n",
            "(128 pred, 95 true)\n",
            "PRECISION: \t0.711\n",
            "RECALL: \t0.958\n",
            "F1 SCORE: \t0.816\n",
            "***********************\n",
            "TAG: IN\n",
            "(2397 pred, 2353 true)\n",
            "PRECISION: \t0.908\n",
            "RECALL: \t0.925\n",
            "F1 SCORE: \t0.916\n",
            "***********************\n",
            "TAG: JJ\n",
            "(1670 pred, 1655 true)\n",
            "PRECISION: \t0.801\n",
            "RECALL: \t0.808\n",
            "F1 SCORE: \t0.805\n",
            "***********************\n",
            "TAG: JJR\n",
            "(45 pred, 47 true)\n",
            "PRECISION: \t0.689\n",
            "RECALL: \t0.660\n",
            "F1 SCORE: \t0.674\n",
            "***********************\n",
            "TAG: JJS\n",
            "(61 pred, 84 true)\n",
            "PRECISION: \t0.852\n",
            "RECALL: \t0.619\n",
            "F1 SCORE: \t0.717\n",
            "***********************\n",
            "TAG: LS\n",
            "(0 pred, 5 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: MD\n",
            "(363 pred, 358 true)\n",
            "PRECISION: \t0.972\n",
            "RECALL: \t0.986\n",
            "F1 SCORE: \t0.979\n",
            "***********************\n",
            "TAG: NFP\n",
            "(0 pred, 60 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: NN\n",
            "(3669 pred, 3336 true)\n",
            "PRECISION: \t0.779\n",
            "RECALL: \t0.857\n",
            "F1 SCORE: \t0.816\n",
            "***********************\n",
            "TAG: NNP\n",
            "(2048 pred, 1816 true)\n",
            "PRECISION: \t0.629\n",
            "RECALL: \t0.709\n",
            "F1 SCORE: \t0.667\n",
            "***********************\n",
            "TAG: NNPS\n",
            "(0 pred, 63 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: NNS\n",
            "(996 pred, 929 true)\n",
            "PRECISION: \t0.735\n",
            "RECALL: \t0.788\n",
            "F1 SCORE: \t0.761\n",
            "***********************\n",
            "TAG: PDT\n",
            "(0 pred, 21 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: POS\n",
            "(87 pred, 84 true)\n",
            "PRECISION: \t0.931\n",
            "RECALL: \t0.964\n",
            "F1 SCORE: \t0.947\n",
            "***********************\n",
            "TAG: PRP\n",
            "(1480 pred, 1487 true)\n",
            "PRECISION: \t0.989\n",
            "RECALL: \t0.985\n",
            "F1 SCORE: \t0.987\n",
            "***********************\n",
            "TAG: PRP$\n",
            "(320 pred, 315 true)\n",
            "PRECISION: \t0.969\n",
            "RECALL: \t0.984\n",
            "F1 SCORE: \t0.976\n",
            "***********************\n",
            "TAG: RB\n",
            "(1115 pred, 1292 true)\n",
            "PRECISION: \t0.899\n",
            "RECALL: \t0.776\n",
            "F1 SCORE: \t0.833\n",
            "***********************\n",
            "TAG: RBR\n",
            "(0 pred, 22 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: RBS\n",
            "(20 pred, 20 true)\n",
            "PRECISION: \t0.450\n",
            "RECALL: \t0.450\n",
            "F1 SCORE: \t0.450\n",
            "***********************\n",
            "TAG: RP\n",
            "(116 pred, 75 true)\n",
            "PRECISION: \t0.500\n",
            "RECALL: \t0.773\n",
            "F1 SCORE: \t0.607\n",
            "***********************\n",
            "TAG: SYM\n",
            "(0 pred, 20 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: TO\n",
            "(410 pred, 359 true)\n",
            "PRECISION: \t0.751\n",
            "RECALL: \t0.858\n",
            "F1 SCORE: \t0.801\n",
            "***********************\n",
            "TAG: UH\n",
            "(58 pred, 116 true)\n",
            "PRECISION: \t0.862\n",
            "RECALL: \t0.431\n",
            "F1 SCORE: \t0.575\n",
            "***********************\n",
            "TAG: VB\n",
            "(1146 pred, 1122 true)\n",
            "PRECISION: \t0.857\n",
            "RECALL: \t0.875\n",
            "F1 SCORE: \t0.866\n",
            "***********************\n",
            "TAG: VBD\n",
            "(503 pred, 520 true)\n",
            "PRECISION: \t0.837\n",
            "RECALL: \t0.810\n",
            "F1 SCORE: \t0.823\n",
            "***********************\n",
            "TAG: VBG\n",
            "(295 pred, 384 true)\n",
            "PRECISION: \t0.827\n",
            "RECALL: \t0.635\n",
            "F1 SCORE: \t0.719\n",
            "***********************\n",
            "TAG: VBN\n",
            "(459 pred, 476 true)\n",
            "PRECISION: \t0.747\n",
            "RECALL: \t0.721\n",
            "F1 SCORE: \t0.734\n",
            "***********************\n",
            "TAG: VBP\n",
            "(759 pred, 771 true)\n",
            "PRECISION: \t0.899\n",
            "RECALL: \t0.885\n",
            "F1 SCORE: \t0.892\n",
            "***********************\n",
            "TAG: VBZ\n",
            "(600 pred, 643 true)\n",
            "PRECISION: \t0.965\n",
            "RECALL: \t0.900\n",
            "F1 SCORE: \t0.932\n",
            "***********************\n",
            "TAG: WDT\n",
            "(91 pred, 106 true)\n",
            "PRECISION: \t0.824\n",
            "RECALL: \t0.708\n",
            "F1 SCORE: \t0.761\n",
            "***********************\n",
            "TAG: WP\n",
            "(122 pred, 113 true)\n",
            "PRECISION: \t0.902\n",
            "RECALL: \t0.973\n",
            "F1 SCORE: \t0.936\n",
            "***********************\n",
            "TAG: WP$\n",
            "(0 pred, 2 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: WRB\n",
            "(112 pred, 113 true)\n",
            "PRECISION: \t1.000\n",
            "RECALL: \t0.991\n",
            "F1 SCORE: \t0.996\n",
            "***********************\n",
            "TAG: XX\n",
            "(0 pred, 3 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: ``\n",
            "(94 pred, 91 true)\n",
            "PRECISION: \t0.819\n",
            "RECALL: \t0.846\n",
            "F1 SCORE: \t0.832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lefzFwCD8AJU",
        "colab_type": "text"
      },
      "source": [
        "## Part 4: Model Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxZ_Wn75uw7n",
        "colab_type": "text"
      },
      "source": [
        "Congratulations, you've just trained a neural network!\n",
        "\n",
        "Now, improve the `LSTMTagger` model and implementing the `init` function in the `FancyTagger` class below. \n",
        "* Feel free to replace the `forward` function inherited from `LSTMTagger` if \n",
        "you need to, but it should not be necessary to receive full credit. Credit will be awarded based on the performance on a holdout test set. \n",
        "* Do not modify any of the cells above when completing part 4. Instead, insert cells below if you need to perform any additional computations. \n",
        "* You are allowed to use any function in `torch.nn`. You are **not** allowed to import any libraries or use implementations copied from the internet. \n",
        "\n",
        "Before submitting, please describe your modifications below:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ya-aaGh6l8D",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "I increased the vocab_size to 50000 and also read in a txt file of increased dimension size 300. This should create a more robust training set. In addition, I added bidirectionality and a dropout of .8 and also a second layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQXnMnCqkhmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 50000\n",
        "embeddings, vocab = read_embeddings('glove.6B.200d.txt', vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKz2PLbu5d8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FancyTagger(LSTMTagger):\n",
        "  \"\"\"\n",
        "  An improved neural model for sequence labeling\n",
        "\n",
        "  Starter code from LSTMTagger has already been provided, but\n",
        "  feel free to change the init and forward function internals\n",
        "  if your model design requires it (though this is not necessary\n",
        "  to receive full credit).\n",
        "\n",
        "  You may use any component in torch.nn. You may NOT\n",
        "  import any additional libraries/modules. \n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, embeddings, hidden_dim, tagset_size):\n",
        "    # initializes the parent LSTMTagger class\n",
        "    # inherits forward, evaluate, and run_training methods\n",
        "    super().__init__(embeddings, hidden_dim, tagset_size)\n",
        "  \n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.num_labels = tagset_size\n",
        "\n",
        "    #############################\n",
        "    # Initialize a PyTorch embeddings layer using the pretrained embedding weights\n",
        "    self.embeddings = nn.Embedding.from_pretrained(embeddings, freeze = False)\n",
        "\n",
        "    # Initialize an LSTM layer, shape batch_size x sequence_len\n",
        "    self.lstm = nn.LSTM(input_size=embeddings.size()[1], hidden_size=hidden_dim, dropout=.8, num_layers=2, bidirectional=True)\n",
        "\n",
        "\n",
        "    # Initialize a single feedforward layer\n",
        "    self.hidden2tag = nn.Linear(self.hidden_dim*2, self.num_labels)\n",
        "    #############################\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUVvXaV7kKe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGDY4ymJvo3h",
        "colab_type": "text"
      },
      "source": [
        "Run the training script below to train the `FancyTagger` model. Again, feel free to adjust any hyperparameters if necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lnp-tWl9Vbo",
        "colab_type": "code",
        "outputId": "26a5be5e-c25c-4aa2-b09d-4aa58bc006e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "model = FancyTagger(embeddings, HIDDEN_SIZE, len(tagset))\n",
        "print(model)\n",
        "model.run_training(train_dataset, dev_dataset, BATCH_SIZE, vocab, tagset,   \n",
        "                   lr=5e-4, num_epochs=15, eval_every=5)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FancyTagger(\n",
            "  (embeddings): Embedding(50000, 200)\n",
            "  (lstm): LSTM(200, 64, num_layers=2, dropout=0.8, bidirectional=True)\n",
            "  (hidden2tag): Linear(in_features=128, out_features=50, bias=True)\n",
            ")\n",
            "**** TRAINING *****\n",
            "Epoch 0 | Loss: 870.2614135742188\n",
            "Epoch 1 | Loss: 319.9044189453125\n",
            "Epoch 2 | Loss: 195.25149536132812\n",
            "Epoch 3 | Loss: 148.35726928710938\n",
            "Epoch 4 | Loss: 123.79181671142578\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9081328295883874\n",
            "**********************\n",
            "Epoch 5 | Loss: 108.72039794921875\n",
            "Epoch 6 | Loss: 97.82007598876953\n",
            "Epoch 7 | Loss: 89.30549621582031\n",
            "Epoch 8 | Loss: 82.90714263916016\n",
            "Epoch 9 | Loss: 77.51448822021484\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9187512427918075\n",
            "**********************\n",
            "Epoch 10 | Loss: 72.11747741699219\n",
            "Epoch 11 | Loss: 68.33991241455078\n",
            "Epoch 12 | Loss: 64.74361419677734\n",
            "Epoch 13 | Loss: 61.292884826660156\n",
            "Epoch 14 | Loss: 58.95886993408203\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9207397096838338\n",
            "**********************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgLM__WZw4wz",
        "colab_type": "text"
      },
      "source": [
        "### Save Predictions\n",
        "\n",
        "When you are satisfied with your `FancyTagger`'s performance on the dev set, run the cell below to write your predictions on the test set to a text file. \n",
        "\n",
        "You can download `predictions.txt` by going to \n",
        "**View > Table of Contents > Files**\n",
        "\n",
        "Please submit this `predictions.txt` file to Gradescope. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddSD3-FN9Zzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert isinstance(model, FancyTagger), 'Please assign your FancyTagger to a variable named model'\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "test_batch_idx, test_batch_lens = test_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for b in range(len(test_batch_idx)):\n",
        "  logits = model.forward(test_batch_idx[b], test_batch_lens[b])\n",
        "  batch_predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "\n",
        "  batch_size, _ = test_batch_idx[b].shape\n",
        "\n",
        "  for i in range(batch_size):\n",
        "    preds = batch_predictions[i]\n",
        "    \n",
        "    seq_len = int(test_batch_lens[b][i])\n",
        "    for j in range(seq_len):\n",
        "      predictions.append(int(preds[j]))\n",
        "  \n",
        "\n",
        "with open('predictions.txt', 'w') as f:\n",
        "  for p in predictions:\n",
        "    f.write(str(p) + \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1s7L3Ra6cNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}